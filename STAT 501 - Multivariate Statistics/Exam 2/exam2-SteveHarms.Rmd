---
title: "Exam 2"
author: "Steve Harms"
date: "April 15, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
library(fmsb)
library(car)
library(GGally)
library(reshape2)
last.PCs.equal.variances <- function(lambda, r = 2, df)
{
  # df = df of the sample variance-covariance matrix
  p <- length(lambda)
  v <- df - (2 * p + 5)/6
  Xi <- v*(r*log(mean(lambda[-(1:(p-r))])) - sum(log(lambda[-(1:(p-r))])))
  return(pchisq(Xi, df = r * (r + 1)/2 -1, lower.tail=F))
}
PCs.proportion.variation.enuff <- function(lambda, q = 1, propn, nobs)
  {
    den <- sum(lambda) # sum of all the eigenvalues
    num <- sum(lambda[1:q]) # sum of the first q eigenvalues
    if (num/den >= propn) return(1)
    else {
      se <- sqrt(2 * sum(lambda[-(1:q)])^2 * sum(lambda[1:q]^2) +
                 2 * sum(lambda[1:q])^2 * sum(lambda[-(1:q)]^2)) /
                   (sqrt(nobs) * den^2)
                                        #asymptotic sd of the test statistic
      test.stat <- (num/den - propn)/se
      return(pnorm(test.stat))
    }
  }
```

#Data Collection and Cleaning
###I will use the NBA data. We can collect data on both team wins and losses, as well as individual player statistics. I will primarily use player statistics in my analysis. I use data from 2010-2019, which I can gather by first writing a few functions. In addition to player information including Name, Position, Age, Team, and Year, I collect several other variables. We can include shooting stats like 3pt Attempts and %, 2pt attempts and %, and FT attempts and %. We can discard the number of shots made, because those variables can be calculated from the above directly. We also have other stats like rebounding (offensive and defensive), assists, steals, blocks, turnovers and personal fouls. Finally, we can include overall measures of player ability and importance like PER (player efficiency rating), Win Shares, Value over replacement player, and Usage rate, which are aggregates of other stats and attempt to evaluate a player's overall effectiveness.
```{r}

#Functions to scrape data from basketball-reference.com

get_nba_standings<-function(year){
urlt <- paste0('https://www.basketball-reference.com/leagues/NBA_',year,'_standings.html')
nbat <- read_html(urlt) %>% html_table() %>% lapply(data.frame)
colnames(nbat[[2]]) = colnames(nbat[[1]])
nbateams <- data.frame(rbind(nbat[[1]],nbat[[2]])) %>% as_tibble()
colnames(nbateams) <- c('Team', colnames(nbat[[1]])[-1])
nbateams <- nbateams %>% 
  select(-GB) %>% type_convert %>% 
  mutate(Team = str_sub(as.character(Team),end=str_locate(as.character(Team),'\\*?\\s*\\([:digit:]+\\)')[,1]-1)) %>%
  mutate(Team=as.factor(Team)) %>%
  mutate(year=as.factor(year)) %>% select(1,8,2:7)
return(nbateams)
}
#####################
#####################
get_player_stats <- function(year){
#basic stats
urlb <- paste0('https://www.basketball-reference.com/leagues/NBA_',year,'_totals.html')
nbaplayers <- read_html(urlb) %>% html_table() %>% data.frame() %>%
  filter(PF != 'PF', Tm!='TOT') %>% as_tibble() %>% type_convert()

#advanced statistics
urla <- paste0('https://www.basketball-reference.com/leagues/NBA_',year,'_advanced.html')
nbaadv <- read_html(urla) %>% html_table() %>% data.frame() %>%
  filter(Pos != 'Pos', Tm!='TOT')  %>% as_tibble() %>% type_convert()

#variables to use for analysis
playerdata <- nbaplayers %>% select(-c(1,9:11,12,15,18,19,24,30)) %>% full_join(nbaadv %>% select(2:5,8,19,24,29)) %>% 
  mutate_at(c(1,2,4), as_factor) %>% mutate(year = as.factor(year)) %>% select(1:4,25,5:24)
return(playerdata)
}

######################################
#collect data

years<- c(2010:2019)
#W-L for each team
teamdata <- suppressWarnings(suppressMessages(
  years %>% lapply(get_nba_standings) %>% lapply(filter, !is.na(Team))%>% lapply(type_convert) %>%
  bind_rows %>% as_tibble() %>% type_convert %>% mutate(year=as.factor(year))
))

#team abbreviations
nodes <- read_html('https://www.basketball-reference.com/leagues/NBA_2019_standings.html') %>% html_nodes('body') %>% html_children() %>% html_nodes('a') %>%
  html_attr('href')
acros <- nodes %>% str_sub(start=str_locate(nodes,'\\/teams\\/')[,2]+1,end=str_locate(nodes,paste0('\\/',2019))[,1]-1) %>% unique()
nbateams <- get_nba_standings(2019) %>% mutate(abbr = as.factor(acros[-1]))  %>% type_convert %>% select(Team,abbr)
nbateams

nbateamdata <- teamdata %>% left_join(nbateams, by=c('Team'='Team')) %>%
  mutate(abbr=as.character(abbr)) %>% select(1,9,2:8)
nbateamdata$abbr[which(nbateamdata$Team=='New Jersey Nets')] <- 'NJN'
nbateamdata

#Player statistics for each year
playerdata <- suppressWarnings(suppressMessages( 
  years %>% lapply(get_player_stats) %>% lapply(type_convert) %>%
    bind_rows %>% as_tibble() %>% type_convert %>%
    mutate(year=as.factor(year)) %>% 
    mutate(FT.=100*FT., X2P.=100*X2P., X3P.=100*X3P.)
  ))

#complete cases only
playerdata <- playerdata %>% filter(complete.cases(.))
#we might also want to adjust for amount of time (in minutes) each player has played
player_perminute <- playerdata %>% mutate_at(c(9,11,13,15:21), funs(./playerdata$MP)) %>%
  filter(complete.cases(.))

#write the data to csv
#not run
#write_csv(nbateamdata, "nbateamdata.csv")
#write_csv(playerdata, "nbaplayerdata.csv")
```

#Data Visualization
###We can explore some of the properties of the player statistics by looking at each variable individually as well as the multivariate relationships:

##Univariate histograms
####We can identify possible cases where normality is violated by looking at each univariate histogram. The variables have heavily skewed distributions in the unadjusted case, however when we adjust by minutes played the distributions look much more approximately normal:
```{r}
#raw data
ggplot(data=(playerdata %>% gather(key=stat, value=value, -c(1:8)))) +
  geom_histogram(aes(x=value)) +
  facet_wrap(.~stat, scales="free")

#per minute data looks more normal
ggplot(data=(player_perminute %>% gather(key=stat, value=value, -c(1:8)))) +
  geom_histogram(aes(x=value)) +
  facet_wrap(.~stat, scales="free")
```

##Pairwise correlations
####We can look at relationships between variables by looking at the pairwise scatterplots, using \code{ggpairs} from the GGally package.
```{r}
ggpairs(playerdata[,9:25])
```

##Correlation Matrix
####The correlation matrices, both adjusted and not, show some interesting positive correlations between # of shots attempted (2,3,and FT) and the "overall aggregate" stats like VORP, WS, USG, and PER. There is also negative correlations between 3P attempts vs. 2P attempts, as well as assists vs. ORB/DRB, which are indicators that there will be a difference between guards who pass and take long shots vs. forwards/centers who take closer shots and collect rebounds. These are also reflected in the pairwise correlation plot.
```{r}
covp <- playerdata %>% select(9:25) %>% var(na.rm=TRUE)
corp <- playerdata %>% select(9:25) %>% cor(use="complete.obs")
covpm <- player_perminute %>% select(9:25) %>% var(na.rm=TRUE)
corpm <- player_perminute %>% select(9:25) %>% cor(use="complete.obs")

ggplot(data = corp %>% melt, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile() + ggtitle("Correlation Matrix - Unadjusted Player Statistics 2010-2019")

ggplot(data = corpm %>% melt, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile() + ggtitle("Correlation Matrix - Adjusted Player Statistics per minute 2010-2019")
```

##QQplot
####Individual normal quantile plots indicate that very few of our variables are normally distributed marginally. The chi-squared plot shows similar results for multivariate normality. However, our sample size is large so we don't need to worry too much about this.
```{r}
#QQplots
QQplot.normal = function(x){
  # x is an observed vector of a variable
  x.sort = sort(x)
  n = length(x)
  p = ( c(1 : n) - 0.5 ) / n
  q = qnorm(p)
  res = data.frame(cbind(x.sort, q))
  names(res) = c("sample.quantile", "normal.quantile")
  return(res)
}

QQs <- apply(playerdata[,-c(1:8)] %>% filter(complete.cases(.)),2,FUN=QQplot.normal) %>% as.data.frame()
QQs <- data.frame(sample.quantile = gather(QQs[,seq(from=1, to=33, by=2)])[,2], 
                  normal.quantile=gather(QQs[,seq(from=2, to=34, by=2)])[,2],
                  var= rep(names(player_perminute)[9:25], each=nrow(QQs)))
ggplot(data = QQs) + geom_point(aes(x=normal.quantile, y=sample.quantile)) +
  facet_wrap(.~var, scales='free')
```

##Group Mean Plots by Position and Year
####We can look for possible differences between the five positions and the ten years to inform a MANOVA or multiple regression analysis. We can see from the plots that there is clearly some differences between the PG means (in purple) and the PF and C positions (green and gold) in every year. However, we can see that in more recent years (2018-19) those differences are not as obvious as in 2010-11. This provides evidence that position classifications are not as important in the modern NBA game.
```{r}
#Plotting variable means by position
summed <- playerdata %>%
  select(-Player,-Tm,-Age,-G,-GS, -MP,-FT.,-X2P.,-X3P.) %>%
  melt(id=c('Pos','year')) %>%
  group_by(Pos,year,variable) %>% summarise(grmean=mean(value))
ggplot(data=(summed)) + geom_line(aes(x=as.factor(variable), group=Pos, y=grmean, color=Pos), size=1.3) +
  facet_wrap(.~year)
```

#Data Analysis
#MANOVA
####From our last plots, we want to investigate whether position, team, and/or year have an effect on the group means of our 17 different stats. The first output shows that, for any choice of test statistic, we have statistically significant evidence that Position is an important factor in the group means for our player statistics.

####The second and third outputs from MANOVA analyses show that in addition to Position, "Year" and "Team" as well as the interactions between Year/Pos and Team/Pos are non-zero. This indicates that the group means for each position are different across years and teams. It should be noted that the p-value for the interaction between year and position is somewhat large for this sample size, indicating that our results are not too conclusive.
```{r}
#MANOVA
#fit linear model with Position as the factor
fitlm <- lm(as.matrix(playerdata[,9:25])~playerdata$Pos)
manova.pos <- Manova(fitlm)
summary(manova.pos)

fitlmtwo <- lm(as.matrix(playerdata[,9:25])~playerdata$Pos * playerdata$Tm)
manova.team <- Manova(fitlmtwo)
summary(manova.team)

fitlmthree <- lm(as.matrix(playerdata[,9:25])~playerdata$Pos*as.factor(playerdata$year))
manova.year <- Manova(fitlmthree)
summary(manova.year)
```

#Multivariate Multiple Linear Regression
####We can do a similar analysis as the MANOVA, except with multiple linear regression. I use minutes played and age in addition to the the factors use above as predictors in the analysis. I start with the most simple MLR model with no interactions, which shows that the coefficients are significantly non-zero. Then I add in year and team as predictors, however the resulting model has coefficients that are not significant at a 5% level. Finally, I fit a third model with interaction between player and team, as in the MANOVA analysis above. Many of these terms are non-zero. However, assessing the fit of these three models with a Likelihood Ratio Test indicates that this third model fits the data best (likely due to large sample size and overfitting).

```{r}
mlrfit.y <- lm(as.matrix(playerdata[,9:25])~playerdata$MP+ playerdata$Age + playerdata$Pos)
summary(mlrfit.y)

mlrfit.r <- lm(as.matrix(playerdata[,9:25])~playerdata$MP+ playerdata$Age + as.factor(playerdata$year) +playerdata$Pos + playerdata$Tm)
#summary(mlrfit.r)

mlrfit <- lm(as.matrix(playerdata[,9:25])~playerdata$MP+ playerdata$Age + as.factor(playerdata$year) +
               playerdata$Pos + playerdata$Tm + playerdata$Pos * playerdata$Tm)
#Likelihood Ratio Test
anova(mlrfit,mlrfit.r, mlrfit.y)

summary(mlrfit)
```

####After the analysis, we can plot the fitted data for a few variables.

####Looking at 3PA across position and year, we can see both the difference between number of 3PA between the positions (expected), but also we can see that all positions have an increasing number of average 3PA attempts over time.
```{r}
ggplot(data=playerdata %>% filter(complete.cases(.)),aes(x=year, y=mlrfit.r$fitted.values[,2])) + geom_line(aes(col=Tm))+
  geom_point(aes(col=Tm)) + facet_wrap(.~Pos, scales='fixed') + 
  ggtitle("3PA by year for each position")+ labs(y="3 point Attempts", x="Year")
```

####Looking at PER rating by Age, there is not much to see. There is little visual evidence that players improve in overall performance as they increase in Age.
```{r}
ggplot(data=playerdata %>% filter(complete.cases(.)),aes(x=Age, y=mlrfit.r$fitted.values[,14])) + geom_line(aes(col=Tm))+
  geom_point(aes(col=Tm)) + facet_wrap(.~Pos, scales='fixed', nrow=1) + 
  ggtitle("PER rating by Age fitted values")+ labs(y="PER rating", x="Age")
```

####We can see from the final fitted values that for any position, the average player improves in their FT shooting ability as they get older (likely due to practice!)
```{r}
ggplot(data=playerdata %>% filter(complete.cases(.)),aes(x=Age, y=mlrfit.r$fitted.values[,6])) + geom_line(aes(col=Tm))+
  geom_point(aes(col=Tm)) + facet_wrap(.~Pos, scales='fixed') + 
  ggtitle("FT% by Age")+ labs(y="FT%", x="Age")
```

#Principal Component Analysis
####We can look at the principal components to analyze the factors that cause the data to vary the most. We first center the data. Using the principal components from the centered data, we can see that 98% of the total variance can be explained by the first five principal components.

```{r}
#centering the data.
playerdata.av <- playerdata[,9:25] %>% filter(complete.cases(.)) %>% summarise_all(mean)
playerdata.centered <- playerdata[,9:25] %>% filter(complete.cases(.)) %>% 
        sweep(MARGIN=2,
        apply(playerdata[,9:25] %>% filter(complete.cases(.)),2,mean)
        )

#principal components
player.pc <- prcomp(playerdata.centered)
player.pc

#we can also just use the default, which automatically centers the data
playerpca <- princomp(playerdata[,9:25])
#how many do we need?
csums <- cumsum(player.pc$sdev^2) / sum(player.pc$sdev^2)
csums
plot(y=csums,x=seq(1:17), type='l')
#is five enough?
PCs.proportion.variation.enuff(player.pc$sdev^2, q = 5, propn = 0.99,
                               nobs = length(playerdata$X3PA))
```

####Looking at the principal components, we can see that the first component is essentially a measure of overall ability (just a linear combination of all of the variables). The 2nd PC shows a contrast between outside players (high in X3PA, X3P., AST, STL and TOV) and inside players (high in X2PA, ORB, DRB, and BLK). The 3rd PC is similar, but places a larger weight on AST and X2PA vs X3PA (indicating a contrast between outside shooters and players who dribble/pass more than shoot). The 4th PC places positive weights on the shooting data and negative loadings on the rebounding/assist/steal/turnovers, indicating a contrast between a "scorer"-type player vs. a "role-player"-type player who is stronger in defense/rebounding. The 5th PC places negative weights on the DRB, FT, and BLK categories, indicating a likely contrast between C/PF positions and the other positions.

####We can also plot the transformed data for the first 2 PCs. We can see that these two PCs alone provide some ability to separate the players by their positions, although it is not perfect (position is not necessarily a clear classification).
```{r}
player.pc

#what do the first 5 PCs represent?
addback <- playerdata.av %>% matrix(ncol=length(playerdata.av), nrow=nrow(playerdata.centered), byrow=T) %>%
  unlist() %>% matrix(ncol=length(playerdata.av), nrow=nrow(playerdata.centered), byrow=F)

plpc.rot <- data.frame(Pos=(playerdata %>% filter(complete.cases(.)))$Pos,
                       ((player.pc$x %>% as.matrix) + addback) %*% player.pc$rotation[,1:5])
plpc.rot %>% group_by(Pos) %>% summarise_all(median)

#looking only at the first two PCs
#Use predict() to get scores

#pl1 <- ((player.pc$x %>% as.matrix) + addback) %*% player.pc$rotation[,1]
#pl2 <- ((player.pc$x %>% as.matrix) + addback) %*% player.pc$rotation[,2]
#pl.tr <- data.frame(Pos=(playerdata %>% filter(complete.cases(.)))$Pos, year=(playerdata %>% filter(complete.cases(.)))$year,
 #                   pc1=pl1, pc2=pl2)
#ggplot(pl.tr) + geom_point(aes(x=pc1,y=pc2, col=Pos))

#pl.tr <- pl.tr %>% filter(Pos%in% c("PG","C"))
#ggplot(pl.tr) + geom_point(aes(x=pc1,y=pc2, col=Pos))

plpca <- predict(playerpca) %>% data.frame(Pos=playerdata$Pos)
ggplot(plpca) + geom_point(aes(x=Comp.1, y=Comp.2, col=Pos))
ggplot(plpca) + geom_point(aes(x=Comp.3, y=Comp.4, col=Pos))
```


#Factor Analysis
####We can also perform Factor analysis to look at factors that explain the data best. I use 3 factors, which is enough to explain 65.8% of the total variance of the data. Looking at the three factors, we see similar interpretations as the PCs. The first factor places large weights on all of the contributors to overall ability. The second factor places larger weights on rebounding/blocks and 2P shots, indicating heavier weights for players who play close to the goal (SF/PF/C). The third factor places much larger weights on 3P shots, assists, and steals, indicating heavier loadings for players who play away from the goal (PG/SG).

####The plots show similar results, we can use the factors to discern the differences in position.
```{r}
playerfact <- factanal(x = playerdata[,9:25], factors = 3, scores = "regression", rotation = "varimax",     method = "mle")
playerfact

#plotting the factor scores
data.frame(Pos=playerdata$Pos,f1=playerfact$scores[,1], f2=playerfact$scores[,2]) %>% 
  ggplot() + geom_point(aes(x=f1,y=f2,col=Pos)) + ggtitle("Factor 1 (Overall ability) and Factor 2 (PF/C) loading")

data.frame(Pos=playerdata$Pos,f2=playerfact$scores[,2], f3=playerfact$scores[,3]) %>% 
  ggplot() + geom_point(aes(x=f2,y=f3,col=Pos)) + ggtitle("Factor 3 (PG/SG) and Factor 2 (PF/C) loading")
```

#Classification
####Now we can try to classify players to their position based on their statistics. We use both linear and quadratic discriminant analysis methods. We have five different positions (classes), so testing for equality of all five covariance matrices is a likely going to reject that hypothesis for at least one case. Instead, we use both LDA and QDA and compare their performances. The two methods have very similar apparent rates of misclassification, 43.2% and 43.7% respectively. Because we prefer a simpler model and it performs slightly better in LOOCV, we prefer LDA in this case. We can see that the two methods predict different classes for 28% of the observations, which is quite significant and indicates that we would have a noticeable difference if we used the other model, even if the actual error rates are similar. The primary issues in our classification seems to be mis-classifying a SF as either PF (power forward) or SG (shooting guard), which makes sense because many players will switch between these positions depending on the situation. We also see some difficulty in classifying C (center) and PF (power forward), two closely-related positions as well. Overall, the apparent error rate is quite high and provides more evidence that "Position" is a more fluid variable than we might believe, especially in the modern NBA.
```{r}
library(MASS)
#cv for lda and qda
linda <- lda(Pos~as.matrix(playerdata[,9:25]), data=playerdata,method='mle', CV=TRUE)
quada <- qda(Pos~as.matrix(playerdata[,9:25]), data=playerdata, method='mle', CV=TRUE)

#How do the two methods compare in predictions?
#lda does very slightly better
#main issue seems to be misclassifying SFs as SGs or PFs and PFs/Cs getting mixed up
table(playerdata$Pos, linda$class)
table(playerdata$Pos, quada$class)
mean(playerdata$Pos != linda$class)
mean(playerdata$Pos != quada$class)

#Do the two methods predict approximately the same classification for each observation?
#28% difference (seems like a lot)
table(linda$class, quada$class)
mean(linda$class != quada$class)
```

#Conclusion
####We have performed five different analyses on the NBA player data. In the MANOVA analysis, we found statistically significant evidence (via the Wilks statistic) that both Position and Team are important factors in explaining the variation in our 17 different player statistics that we collected. In the multivariate linear regression analysis we found a similar result, however many of the regression coefficients for teams are not significantly non-zero (even with large sample size). Even though we included many insignificant terms in our model, we still found that the full model fit the data better than other reduced models via Likelihood ratio test. We also found that minutes played (MP) and age had a significant positive relationship with all of the variables.

####Looking at dimension reduction techniques, we found in both PCA and Factor analysis that much of the variation in the data can be explained by a few (<5) factors. These factors/principal components can be best interpreted as measures of overall ability, contrast between guards and forwards, contrasts between inside and outside players, and contrasts between high scorers vs. role players/defenders/rebounders. While using this data to try and classify players to their positions, we found it difficult because of the similarities in the data between SFs and their closely related positions of SG and PF, and thus there may be other, better ways to classify players beyond just position.

####One key assumption underlying most of these models is that our variables follow a multivariate normal distribution, which is likely not the case based on our visual analysis of quantile plots. However, we should note that our sample size is quite large and thus our results are likely robust to departures from this assumption.