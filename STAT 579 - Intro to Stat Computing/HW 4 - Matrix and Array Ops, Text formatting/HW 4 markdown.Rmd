---
title: "HW 4 markdown"
author: "Steve Harms"
date: "September 24, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Exercise 1
##a)
```{r}
#Read in the data
votes <- read.table(file = "http://maitra.public.iastate.edu/stat579/datasets/senate-109.txt", sep = "\t", header = TRUE)

#Give some names to our columns
names(votes$bill_type_bill_name_bill_ID)= "type.name.ID"
names(votes$missing_votes)= "missing"
#Make sure we have the right format for our first column
votes$bill_type_bill_name_bill_ID <- as.character(votes$bill_type_bill_name_bill_ID)
```

##b)
###i)
```{r}
#Use sub() to get everything before the first _, combine it all into one vector
billtype <- cbind(sub("_.*$", "", votes$bill_type_bill_name_bill_ID))
colnames(billtype) = "billtype"
```

###ii)
```{r}
#A frequency table of the types of bills (it's a pretty big list)
table(billtype)
```

##c)
```{r}
#first, create a matrix with only the actual votes and exclude the bills and missing votes columns
votesonly <- as.matrix(votes[,-(1:2)])
#Get XX', then get the values of its diagonal
votecount1 <- votesonly%*%t(votesonly)
votecount <- diag(votecount1)

#Compare our recorded votes and missing votes with our total number of senators to see if any were not accounted for
matches <- votecount + votes$missing_votes == 100
sum(matches)
```

**We have 441 matches for 441 bills, so there are no discrepancies. All votes have been accounted for.**

##d)
```{r}
#First, create the subset where Senator Frist cast a vote (either 1 or -1)
relative1 <- subset(cbind(billtype,votes), votes$William.H..Bill.Frist..TN. != 0)

#Then, recode (votes only) relative to Frist's votes. "Indifferent" means they did not cast a vote
relative <- relative1[,-(1:3)]
relative[relative == relative$William.H..Bill.Frist..TN.] <- "With"
relative[relative != relative$William.H..Bill.Frist..TN. & relative != 0] <- "Against"
relative[relative == 0] <- "Indifferent"

#And now we have a matrix of votes relative to Senator Frist's votes
```

##e)
```{r}
#I'm using reshape to get my data into an easier to use format
require(reshape2)

#recombine the bill type vector from earlier with our new votes matrix
party <- cbind(relative1[,1], relative)
names(party)[1] <- "billtype"

#Then melt the data (using reshape2) so that For/Against/Indifferent is its own column
party2 <- melt(party, id.vars = "billtype", variable_name = "Senator", value.name = "ForAgainst")

#Create a frequency table of votes by bill type
table1 <- table(party2$billtype, party2$ForAgainst)
#Then use prop.table to get percentages of the totals
percentages <- prop.table(table1,1)
percentages
```


#Exercise 2
##a) **See note about reversing columns/rows**
```{r}
#Read the data into a matrix
pet <- matrix(scan(file = "http://maitra.public.iastate.edu/stat579/datasets/fbp-img.dat"), nrow = 128, ncol = 128, byrow = TRUE)

#Reverse the order of the columns so image() reads it in correctly. In class we reversed columns,
#but based on the information given in the assignment it appears we want to reverse row order instead?
#I can't tell which brain image looks correct
brain <- pet[,128:1]
```

##b)
```{r}
require(grDevices); require(graphics);
#An image of our PET brain scan
image(z=brain, col = topo.colors(40), main = "PET Scan of FDG-18 Intake", axes = F, asp = 1)

```

##c)
###i
```{r}
#First we find the range of our brain data
range(brain)
#Then create 8 equally spaced bins
binwidth <- (max(brain) - min(brain))/8
#Create a sequence of midpoints for each bin
midpts <- seq(from= min(brain)+ binwidth/2, by = binwidth, length = 8)
#bin the data using apply() on each column of the data. cut() seperates the data into 8 bins
binned1 <- apply(brain, 2, cut, seq(from=min(brain), to=max(brain), length = 9), labels = midpts)
#change our bin labels to numeric
binned2 <- apply(binned1, 2, as.numeric)

#an image of our new binned data
image(z=binned2, col = topo.colors(40), main = "PET Scan of FDG-18 Intake", axes = F, asp = 1)
```

###ii
```{r}
#A function to find quantiles based on the methods discussed in lecture
#Easier than the way I did it
bin <- function(b, n){
  #Find quantiles and the mid points of those quantile bins
  b.qt <- quantile(b, probs = seq(0, 1, length = n))
  b.qt.mid <- (b.qt[-1] + b.qt[-length(b.qt)])/2
  #stack data matrix and midpoint n times on top of each other
  b.arr <- array(b, dim = c(dim(b), length(b.qt.mid)))
  mid.arr <- array(rep(b.qt.mid,
                       each = prod(dim(b))), dim = dim(b.arr))
  #Find squared difference between each point and the possible mid points
  sq.diff.arr <- (b.arr - mid.arr)^2
  #Create new matrices that pick the smallest distance between the points and the mid points
  min.idb1 <- apply(X = sq.diff.arr, MAR = c(1,2), FUN = which.min)
  min.idb2 <- apply(X = sq.diff.arr, MAR = c(1,2), FUN = order, decreasing = F)[1,,]
  #Recode the data to be the binned data
  b.quant <- array(b.qt.mid[min.idb1], dim = dim(b))
  return(b.quant)
}
#Then Just run the function with n = 9 (for 8 bins)
brain.quant <- bin(brain, 9)

#A third plot of our brain scan
image(z=brain.quant, col = topo.colors(40), main = "PET Scan of FDG-18 Intake", axes = F, asp = 1)
```

###iii
**When we bin the data based on quantiles, it is not a linear transformation of the data, so the coloring is distorted based on the distribution. Since the distribution of the values is not uniform over the range, the bins will be unevenly spaced and sized based on the distribution, which is different from the simple linear binning from the previous part. Note that the first raw image is similar to the raw data, but shows a slightly sharper contrast for the high values. **

#Exercise 3
##a)
```{r}
#Read in the data
auto <- read.table(file= "auto.txt", header=T, sep="")
```

##b)
```{r}
#Create our data matrices, with a column of 1s for the intercept term
x <- cbind(rep(1, times = length(auto$horsepower)), auto$horsepower)
y <- auto$mpg

#Estimate our least squares coefficients using standard matrix operations.
b0b1 <- solve(t(x)%*%x)%*%(t(x))%*%y
#The result is a 2x1 matrix with the first entry being our intercept and the second our slope
b0b1
```

##c)
```{r}
#Now estimate using the lm() function
model <- lm(auto$mpg~auto$horsepower)
model
```

**As should be expected for this simple model, the regression coefficients are the same for each method.**